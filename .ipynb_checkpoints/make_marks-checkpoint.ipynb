{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4316552-2acc-44b5-b5ab-78c9c7cf743f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ept_mark import mark\n",
    "from headers_new import *\n",
    "import json,os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b356b813-afd4-44ae-83d4-81df385380c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'output': 'tCl lCl mPk',\n",
    "          'l_max_scalars': 1000,\n",
    "          'lensing': 'yes',\n",
    "          'P_k_max_h/Mpc': 3.,\n",
    "          'non linear':'halofit', \n",
    "          'z_pk': '0.0,1087',\n",
    "          'A_s': 2.0830e-9,\n",
    "          'n_s': 0.9649,\n",
    "          'alpha_s': 0.,\n",
    "          'h': 0.6736,\n",
    "          'N_ur': 2.0328,\n",
    "          'N_ncdm': 1,\n",
    "          # 'm_ncdm': '0.01,0.05',\n",
    "          'tau_reio': 0.0544,\n",
    "          'omega_ncdm': 0.00064420,\n",
    "          'omega_b': 0.02237,\n",
    "          'omega_cdm': 0.1200,\n",
    "          'Omega_k': 0.}\n",
    "cosmo = Class() \n",
    "cosmo.set(params) \n",
    "cosmo.compute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd504a8-9664-4caa-ad98-addf69d456bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmin = 5e-4\n",
    "kmax = 1.\n",
    "Nk = 500\n",
    "h = cosmo.pars['h']\n",
    "z= 1.1 ###1.\n",
    "k = np.logspace(np.log10(kmin),np.log10(kmax),Nk) # [h/Mpc]\n",
    "plin = np.array([cosmo.pk_cb_lin(kk*h,z)*h**3. for kk in k]) \n",
    "f = cosmo.scale_independent_growth_factor_f(z)\n",
    "pars = [1,0,0,0,0,0,0,0,0,0,0]#b1, b2, bs, b3, alpha0, alpha2, alpha4, alpha6, sn, sn2, sn4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56280403-7f9f-4204-95d2-1374d802be1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pars(path,EPT=True):\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "\n",
    "    # Strips the newline character\n",
    "    param_labels = Lines[0].split()\n",
    "    param_labels = param_labels[1:]\n",
    "    params = Lines[1].split()\n",
    "    \n",
    "    p_names = ['b1','b2','bs','b3','alpha0','alpha2','alpha4','alpha6','SN0','SN2','SN4']\n",
    "    LPT_params = []\n",
    "    for pp in p_names:\n",
    "        if pp in param_labels: LPT_params.append(float(params[param_labels.index(pp)]))\n",
    "        elif pp=='b1': LPT_params.append(1)\n",
    "        else: LPT_params.append(0)\n",
    "    LPT_params[0] -= 1\n",
    "    if not EPT: return LPT_params\n",
    "    \n",
    "    EPT_params = np.zeros(len(p_names))\n",
    "    EPT_params[-7:] = LPT_params[-7:]\n",
    "    EPT_params[0] = LPT_params[0] + 1\n",
    "    EPT_params[1] = LPT_params[1] + 8/21 * LPT_params[0]\n",
    "    EPT_params[2] = LPT_params[2] - 2/7 * LPT_params[0]\n",
    "    EPT_params[3] = LPT_params[3] # just leave b3.... not sure what to do with it\n",
    "    \n",
    "    return EPT_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4150cf41-b94d-424b-ad53-e34b13474776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, 0, 0]\n",
      "m04\n",
      "[0, -1, 0, 0]\n",
      "R10\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R10_matter\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R10_LRG\n",
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R20_matter\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R20_LRG\n",
      "[0, -1, 0, 0]\n",
      "R30\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R30_matter\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R30_LRG\n"
     ]
    }
   ],
   "source": [
    "# computes necessary integrals\n",
    "# this takes pretty long\n",
    "z_list = [1.1]\n",
    "mark_list = ['m04']\n",
    "Rs = [10,20,30]\n",
    "for mm in mark_list.copy():\n",
    "    for RR in Rs:\n",
    "        mark_list.append(mm+'_R%d'%RR)\n",
    "\n",
    "space_list = ['rsd']\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "stoch = False\n",
    "if not stoch: stoch_str = ''\n",
    "else: \n",
    "    stoch_str='_stoch'\n",
    "    # stoch_str='_stoch2'\n",
    "for zz in z_list:\n",
    "    for m_name in mark_list:\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        # matter \n",
    "        pars = get_pars('fits/rsd_matterfit_pkmu.minimum.txt')\n",
    "        print(pars)\n",
    "        for ss in space_list:\n",
    "            gen_name = '%s/z%.3f/%s_matter'%(ss,zz,m_name)\n",
    "            print(gen_name)\n",
    "            plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in k]) \n",
    "            f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "            temp_mark = mark(k,plin,nk=200,Cn=Cn,R=Rcut,name=gen_name,N=5000,basedir='.')\n",
    "            # temp_mark.Nskip=Nk\n",
    "            temp_mark.Nskip=25\n",
    "            if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "            elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "            \n",
    "\n",
    "            filename = 'output/rsd/z1.100/%s_matter/integral13_unity%s.json'%(m_name[-3:],stoch_str)\n",
    "            if not os.path.exists(filename):\n",
    "            # if True:\n",
    "                integral13_unity = temp_mark.compute_integral13_table(pars,f,unity=True,stoch=stoch)\n",
    "                dump_dict = {'table':integral13_unity.tolist()}\n",
    "                with open(filename, 'w') as fp:\n",
    "                    json.dump(dump_dict, fp)        \n",
    "            filename = 'output/rsd/z1.100/%s_matter/integral13%s.json'%(m_name[-3:],stoch_str)\n",
    "            if not os.path.exists(filename):\n",
    "            # if True:\n",
    "                integral13 = temp_mark.compute_integral13_table(pars,f,stoch=stoch)\n",
    "                dump_dict = {'table':integral13.tolist()}\n",
    "                with open(filename, 'w') as fp:\n",
    "                    json.dump(dump_dict, fp)\n",
    "\n",
    "            W_R_int = temp_mark.W_R(temp_mark.kint)\n",
    "            plin_p = temp_mark.plin_p\n",
    "                \n",
    "            filename = 'output/rsd/z1.100/%s_matter/integral22_W%s.json'%(m_name[-3:],stoch_str)\n",
    "            if not os.path.exists(filename):\n",
    "            # if True:\n",
    "            # if True and Rcut!=30 and Rcut !=10 and Rcut !=20:\n",
    "                integral22_W = temp_mark.compute_integral22_table(pars,f,W_R_int*plin_p,stoch=stoch)\n",
    "                dump_dict = {'table':integral22_W.tolist()}\n",
    "                with open(filename, 'w') as fp:\n",
    "                    json.dump(dump_dict, fp)            \n",
    "            \n",
    "        # LRG\n",
    "        pars = get_pars('fits/rsd_bfit_pkmu.minimum.txt')\n",
    "        print(pars)\n",
    "        for ss in space_list:\n",
    "            # gen_name = '%s/z%.3f/%s_matter'%(ss,zz,m_name)\n",
    "            gen_name = '%s/z%.3f/%s_LRG'%(ss,zz,m_name)\n",
    "            print(gen_name)\n",
    "            plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in k]) \n",
    "            f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "            temp_mark = mark(k,plin,nk=200,Cn=Cn,R=Rcut,name=gen_name,N=5000,basedir='.')\n",
    "            # temp_mark.Nskip=Nk\n",
    "            temp_mark.Nskip=25\n",
    "            if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "            elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "            filename = 'output/rsd/z1.100/%s_LRG/integral13_unity%s.json'%(m_name[-3:],stoch_str)\n",
    "            if not os.path.exists(filename):\n",
    "                integral13_unity = temp_mark.compute_integral13_table(pars,f,unity=True,stoch=stoch)\n",
    "                dump_dict = {'table':integral13_unity.tolist()}\n",
    "                with open(filename, 'w') as fp:\n",
    "                    json.dump(dump_dict, fp)        \n",
    "            filename = 'output/rsd/z1.100/%s_LRG/integral13%s.json'%(m_name[-3:],stoch_str)\n",
    "            if not os.path.exists(filename):\n",
    "                integral13 = temp_mark.compute_integral13_table(pars,f,stoch=stoch)\n",
    "                dump_dict = {'table':integral13.tolist()}\n",
    "                with open(filename, 'w') as fp:\n",
    "                    json.dump(dump_dict, fp)\n",
    "                \n",
    "            W_R_int = temp_mark.W_R(temp_mark.kint)\n",
    "            plin_p = temp_mark.plin_p\n",
    "\n",
    "            filename = 'output/rsd/z1.100/%s_LRG/integral22_W%s.json'%(m_name[-3:],stoch_str)\n",
    "            if not os.path.exists(filename):\n",
    "            # if True and Rcut != 10 and Rcut != 20 and Rcut != 30:\n",
    "                integral22_W = temp_mark.compute_integral22_table(pars,f,W_R_int*plin_p,stoch=stoch)\n",
    "                dump_dict = {'table':integral22_W.tolist()}\n",
    "                with open(filename, 'w') as fp:\n",
    "                    json.dump(dump_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebed0c4-27d3-4b5a-a3d0-708ea7a64aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_Cn_vec(Cn,Cn2=None):\n",
    "    C0, C1, C2, C3 = Cn\n",
    "    if Cn2 is None: C0_2, C1_2, C2_2, C3_2 = Cn\n",
    "    else: C0_2, C1_2, C2_2, C3_2 = Cn2\n",
    "    return [C0*C0_2, (C0*C1_2+C0_2*C1)/2, (C0* C2_2 +C0_2* C2 )/2, (C0* C3_2 +C0_2* C3 )/2,\n",
    "            C1*C1_2, (C1*C2_2+C1_2*C2)/2, (C1*C3_2+C1_2*C3)/2, C2*C2_2, (C2*C3_2+C2_2*C3)/2]\n",
    "    # return [C0**2, C0* C1, C0 *C2, C0 *C3, C1**2, C1 *C2, C1* C3, C2**2, C2*C3]\n",
    "def combine_mark_params(Cn,table,change=False,Cn2=None):\n",
    "    if change: \n",
    "        Cn_new = [Cn[i]*(-1)**i for i in range(len(Cn))]\n",
    "    else: Cn_new = Cn    \n",
    "    if Cn2 is not None: \n",
    "        if change: Cn2_new = [Cn2[i]*(-1)**i for i in range(len(Cn2))]\n",
    "        else: Cn2_new = Cn2\n",
    "    else: Cn2_new = None\n",
    "    # print(Cn_new,Cn2_new)\n",
    "    Cn_vec = get_Cn_vec(Cn_new,Cn2=Cn2_new)\n",
    "    return np.einsum('i,ijk->jk',Cn_vec,table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "128b8b38-cd44-4e7a-ab46-88d79c157b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThese are blocks reserved for storing content so that the marked classes don't need to be called anywhere else this is for \\nMATTER\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "These are blocks reserved for storing content so that the marked classes don't need to be called anywhere else this is for \n",
    "MATTER\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b80768-a833-47ce-a254-4b990f23e8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, 0, 0]\n",
      "m04\n",
      "[0, -1, 0, 0]\n",
      "R10\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R10_matter\n",
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R20_matter\n",
      "[0, -1, 0, 0]\n",
      "R30\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R30_matter\n"
     ]
    }
   ],
   "source": [
    "# code to save tables for each radii \n",
    "\n",
    "# matter\n",
    "z_list = [1.1]\n",
    "mark_list = ['m04']\n",
    "Rs = [10,20,30]\n",
    "# Rs = [10,20,30]\n",
    "for mm in mark_list.copy():\n",
    "    for RR in Rs:\n",
    "        mark_list.append(mm+'_R%d'%RR)\n",
    "\n",
    "space_list = ['rsd']\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for zz in z_list:\n",
    "    for m_name in mark_list:\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        # matter \n",
    "        pars = get_pars('fits/rsd_matterfit_pkmu.minimum.txt')\n",
    "        print(pars)\n",
    "        for ss in space_list:\n",
    "            gen_name = '%s/z%.3f/%s_matter'%(ss,zz,m_name)\n",
    "            # gen_name = '%s/z%.3f/%s_LRG'%(ss,zz,m_name)\n",
    "            print(gen_name)\n",
    "            plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in k]) \n",
    "            f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "            temp_mark = mark(k,plin,nk=200,Cn=Cn,R=Rcut,name=gen_name,N=5000,basedir='.')\n",
    "            if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "            elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "                        \n",
    "            stoch = False\n",
    "            if stoch: stoch_str = '_stoch'\n",
    "            else: stoch_str = ''\n",
    "            M13B_table_new = temp_mark.compute_M13B_table(pars,f,stoch=stoch)\n",
    "            M13C_table_new = temp_mark.compute_M13C_table(pars,f)\n",
    "            M22B_table_new = temp_mark.compute_M22B_table(pars,f,stoch=stoch)\n",
    "            M22C_table_new = temp_mark.compute_M22C_table(pars,f)\n",
    "            CdCdP_table_new = temp_mark.compute_CdCdP_table(pars,f)\n",
    "            stoch_SN_table = temp_mark.compute_stoch_SN_table(pars,f,stoch=stoch)\n",
    "            stoch_BSN_table = temp_mark.compute_stoch_BSN_table(pars,f)\n",
    "            stoch_dof_table = temp_mark.compute_stoch_dof_table(pars,f)\n",
    "            \n",
    "            \n",
    "            filename = 'output/rsd/z1.100/%s_matter/M_tables%s.json'%(m_name[-3:],stoch_str)\n",
    "            dump_dict = {'M13B':M13B_table_new.tolist(),\n",
    "                         'M13C':M13C_table_new.tolist(),\n",
    "                         'M22B':M22B_table_new.tolist(),\n",
    "                         'M22C':M22C_table_new.tolist(),\n",
    "                         'CdCdP':CdCdP_table_new.tolist(),\n",
    "                         'stoch_SN':stoch_SN_table.tolist(),\n",
    "                         'stoch_BSN':stoch_BSN_table.tolist(),\n",
    "                         'stoch_dof':stoch_dof_table.tolist(),\n",
    "                         }\n",
    "            with open(filename, 'w') as fp:\n",
    "                json.dump(dump_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9f0ccc-0196-409b-9ef3-44bf9ba00ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_dict = {'test':'test'}\n",
    "# reset json file\n",
    "filename = 'fits/matter_rsd_analytical.json'\n",
    "# filename = 'fits/matter_rsd_analytical_stoch.json'\n",
    "# filename = 'fits/rsd_analytical.json'\n",
    "\n",
    "# Write the empty dictionary to a JSON file\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(empty_dict, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281d1ea6-3ccf-4b1d-bfac-d22dd44c41cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, 0, 0]\n",
      "m04\n",
      "[0, -1, 0, 0]\n",
      "R10\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R10_matter\n",
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R20_matter\n",
      "[0, -1, 0, 0]\n",
      "R30\n",
      "[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "  5.0066198e-01 -1.9638121e+01  0.0000000e+00  0.0000000e+00\n",
      "  0.0000000e+00 -3.8849323e+03  0.0000000e+00]\n",
      "rsd/z1.100/m04_R30_matter\n"
     ]
    }
   ],
   "source": [
    "# then code to save each spectra\n",
    "z_list = [1.1]\n",
    "mark_list = ['m04']\n",
    "# Rs = [10,20,30,50,100]\n",
    "# Rs = [10,20,30,50]\n",
    "Rs = [10,20,30]\n",
    "for mm in mark_list.copy():\n",
    "    for RR in Rs:\n",
    "        mark_list.append(mm+'_R%d'%RR)\n",
    "\n",
    "# mark_list = ['m04_R30']\n",
    "\n",
    "# space_list = ['real','rsd']\n",
    "space_list = ['rsd']\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for zz in z_list:\n",
    "    for m_name in mark_list:\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        # matter \n",
    "        pars = get_pars('fits/rsd_matterfit_pkmu.minimum.txt')\n",
    "        print(pars)\n",
    "        for ss in space_list:\n",
    "            gen_name = '%s/z%.3f/%s_matter'%(ss,zz,m_name)\n",
    "            print(gen_name)\n",
    "            plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in k]) \n",
    "            f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "            temp_mark = mark(k,plin,nk=200,Cn=Cn,R=Rcut,name=gen_name,N=5000,basedir='.')\n",
    "            # temp_mark.Nskip=Nk\n",
    "            temp_mark.Nskip=40\n",
    "            if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "            elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "            \n",
    "            stoch = False\n",
    "            if stoch: stoch_str = '_stoch'\n",
    "            else: stoch_str = ''\n",
    "            \n",
    "            filename = 'output/rsd/z1.100/%s_matter/M_tables%s.json'%(m_name[-3:],stoch_str)\n",
    "            with open(filename, 'r') as json_file:\n",
    "                table_data = json.load(json_file)\n",
    "            M13B_table_new = np.array(table_data['M13B'])\n",
    "            M13C_table_new = np.array(table_data['M13C'])\n",
    "            M22B_table_new = np.array(table_data['M22B'])\n",
    "            M22C_table_new = np.array(table_data['M22C'])\n",
    "            CdCdP_table_new = np.array(table_data['CdCdP'])\n",
    "            stoch_SN_table_new = np.array(table_data['stoch_SN'])\n",
    "            stoch_BSN_table_new = np.array(table_data['stoch_BSN'])\n",
    "            stoch_dof_table_new = np.array(table_data['stoch_dof'])\n",
    "            \n",
    "            for i,key in enumerate(data):\n",
    "                if key[-3:]!=m_name[-3:]: continue\n",
    "                Cn = data[key]['Cn']\n",
    "                for j,key2 in enumerate(data):\n",
    "                    if i>j:continue\n",
    "                    if key2[-3:]!=m_name[-3:]: continue\n",
    "                    if key!=key2 and key[:3]!='m00':continue\n",
    "                    Cn2 = data[key2]['Cn']\n",
    "                    # print(key+'_'+key2,Rcut)\n",
    "                    # input to dict\n",
    "                    M13_new = combine_mark_params(Cn,M13B_table_new + M13C_table_new,change=True,Cn2=Cn2)\n",
    "                    M13B_new = combine_mark_params(Cn,M13B_table_new,change=True,Cn2=Cn2)\n",
    "                    M13C_new = combine_mark_params(Cn,M13C_table_new,change=True,Cn2=Cn2)\n",
    "                    M22_new = combine_mark_params(Cn,M22B_table_new + M22C_table_new,change=True,Cn2=Cn2)\n",
    "                    M22B_new = combine_mark_params(Cn,M22B_table_new,change=True,Cn2=Cn2)\n",
    "                    M22C_new = combine_mark_params(Cn,M22C_table_new,change=True,Cn2=Cn2)\n",
    "                    CdCdP_new = combine_mark_params(Cn,CdCdP_table_new,change=True,Cn2=Cn2)\n",
    "                    stoch_SN_new = combine_mark_params(Cn,stoch_SN_table_new,change=True,Cn2=Cn2)\n",
    "                    stoch_BSN_new = combine_mark_params(Cn,stoch_BSN_table_new,change=True,Cn2=Cn2)\n",
    "                    stoch_dof_new = combine_mark_params(Cn,stoch_dof_table_new,change=True,Cn2=Cn2)\n",
    "\n",
    "                    for table in [M13_new,M13B_new,M13C_new,M22_new,M22B_new,M22C_new,stoch_SN_new,stoch_dof_new,stoch_BSN_new]:\n",
    "                        table[3:] *= 0\n",
    "\n",
    "                    M13_new = temp_mark.poly2leg(M13_new)\n",
    "                    M13B_new = temp_mark.poly2leg(M13B_new)\n",
    "                    M13C_new = temp_mark.poly2leg(M13C_new)\n",
    "                    M22_new = temp_mark.poly2leg(M22_new)\n",
    "                    M22B_new = temp_mark.poly2leg(M22B_new)\n",
    "                    M22C_new = temp_mark.poly2leg(M22C_new)\n",
    "                    CdCdP_new = temp_mark.poly2leg(CdCdP_new)\n",
    "\n",
    "                    stoch_BSN_new = temp_mark.poly2leg(stoch_BSN_new) # this shouldn't matter\n",
    "                    stoch_SN_new = temp_mark.poly2leg(stoch_SN_new)\n",
    "                    stoch_dof_new = temp_mark.poly2leg(stoch_dof_new)\n",
    "\n",
    "                    tot_M = 2*M13_new + M22_new + CdCdP_new \n",
    "                    tot_M_st = 2*M13_new + M22_new + CdCdP_new + stoch_SN_new\n",
    "\n",
    "\n",
    "                    # read current dict\n",
    "                    anal_file = 'fits/matter_rsd_analytical%s.json'%stoch_str\n",
    "                    with open(anal_file, 'r') as json_file:\n",
    "                        write_data = json.load(json_file)\n",
    "\n",
    "                    # The new data to add to the dictionary\n",
    "                    new_data = {\n",
    "                        key+'_'+key2: {\n",
    "                            'k': temp_mark.kv.tolist(),\n",
    "                            'M_ell': tot_M.tolist(),\n",
    "                            'Mst_ell': tot_M_st.tolist(),\n",
    "                            'stoch_BSN_ell': stoch_BSN_new.tolist(),\n",
    "                            'stoch_SN_ell': stoch_SN_new.tolist(),\n",
    "                            'stoch_dof_ell': stoch_dof_new.tolist(),\n",
    "                            'CdCdP_ell': CdCdP_new.tolist(),\n",
    "                            'M13_ell': M13_new.tolist(),\n",
    "                            'M13B_ell': M13B_new.tolist(),\n",
    "                            'M13C_ell': M13C_new.tolist(),\n",
    "                            'M22_ell': M22_new.tolist(),\n",
    "                            'M22B_ell': M22B_new.tolist(),\n",
    "                            'M22C_ell': M22C_new.tolist(),\n",
    "                            'pars': pars.tolist()\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    # Update the existing dictionary with the new data\n",
    "                    write_data.update(new_data)\n",
    "\n",
    "                    # Write the updated dictionary back to the JSON file\n",
    "                    with open(anal_file, 'w') as json_file:\n",
    "                        json.dump(write_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bec177a-722c-47ac-853a-91e7970f39d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define cov Legendre transform function\n",
    "\n",
    "def LegendreTrans_Cov(l,p,lp=None,mu_max=1.,Nk=500,Nmu=50):\n",
    "  '''\n",
    "  Returns the l'th multipole of |P(k,mu), where P(k,mu) is a \n",
    "  vector of length Nk*Nmu. Returns a vector of length Nk.\n",
    "  '''\n",
    "  if lp is None: lp = l\n",
    "  # n = self.Nk ; m = self.Nmu\n",
    "  n = Nk; m = Nmu\n",
    "  # mu = self.mu.reshape((n,m))[0]\n",
    "  mu = np.linspace(0.,1.,50)\n",
    "  # MU = np.tile(mu,Nk)\n",
    "  # mu = self.mu.reshape((n,m))[0]\n",
    "  p_reshaped = p.reshape((n,m))\n",
    "  result = np.zeros(n)\n",
    "  for i in range(n):\n",
    "     integrand = (2*l+1)*(2*lp+1)*p_reshaped[i,:]*scipy.special.legendre(l)(mu)*scipy.special.legendre(lp)(mu)\n",
    "     result[i] = scipy.integrate.simps(integrand,x=mu)\n",
    "  return result\n",
    "\n",
    "def call_markspec(m_name1,m_name2):\n",
    "    \n",
    "    simid_list = ['AbacusSummit_base_c000_ph000','AbacusSummit_base_c000_ph001','AbacusSummit_base_c000_ph002','AbacusSummit_base_c000_ph003']\n",
    "    zz = 1.1\n",
    "    ss = 'rsd'\n",
    "\n",
    "    d_pkmu_list = []\n",
    "    dd_list = []\n",
    "\n",
    "    for simid in simid_list:\n",
    "        ff = open('/mocks/results/'+simid+'/z%.3f/%s_pk3d.json'%(zz,ss))\n",
    "        # ff = open(self.datfn)\n",
    "        simdata = json.load(ff)\n",
    "        sim_k = np.array(simdata['k_binc'])\n",
    "        k = np.array(simdata['k_binc'])\n",
    "        Nk = len(k)\n",
    "        Nmu = 50\n",
    "        mu = np.linspace(0.,1.,Nmu)\n",
    "        MU = np.tile(mu,Nk)\n",
    "        dmu = list(mu[1:]-mu[:-1])\n",
    "        dmu.append(dmu[-1])\n",
    "        dmu = np.array(dmu)\n",
    "\n",
    "        dk = list(k[1:]-k[:-1])\n",
    "        dk.insert(0,dk[0])\n",
    "        dk = np.array(dk)\n",
    "        k = np.repeat(k,Nmu)\n",
    "        dk = np.repeat(dk,Nmu)\n",
    "        dmu = np.tile(dmu,Nk)\n",
    "\n",
    "        dd = simdata['matter_%s_matter_%s_ell'%(m_name1,m_name2)]#[:,0]\n",
    "        dd = np.array(dd)\n",
    "        dd_list.append(dd)\n",
    "        dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu),np.repeat(dd[:,2],Nmu)])\n",
    "        d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]+0.125*(35*MU**4-30*MU**2+3)*dvec[2]\n",
    "        d_pkmu_list.append(d_pkmu)\n",
    "\n",
    "\n",
    "    dd_list = np.array(dd_list)\n",
    "    d_pkmu_list = np.array(d_pkmu_list)\n",
    "    # print(np.allclose(d_ell_list[0,0],d_ell_list.reshape((len(simid_list),3*Nk))[0,:Nk]))\n",
    "    dd_avg = np.average(dd_list,axis=0)\n",
    "    d_pkmu_avg = np.average(d_pkmu_list,axis=0)\n",
    "\n",
    "    Vsurvey = (2e3)**3\n",
    "\n",
    "    prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.)\n",
    "    Cov = prefactor*2*d_pkmu_avg**2\n",
    "    knl=0.2959184739328827\n",
    "    kmin = 0.003\n",
    "    kmax = knl\n",
    "\n",
    "\n",
    "    k_constraint = (k>kmin)*(k<kmax)\n",
    "    # Cov += 1e-20\n",
    "    Cinv = 1/Cov\n",
    "    Cinv *= k_constraint\n",
    "    # Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "    save_dict = {'simid_list':simid_list,'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "                 'd_pkmu':d_pkmu_avg.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd_avg.T.tolist(), 'k':sim_k.tolist()}\n",
    "    return save_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "196ca95e-372c-406b-94d7-6b344bdd3c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_dict = {'test':'test'}\n",
    "# reset json file\n",
    "filename = 'fits/matter_rsd_simulation.json'\n",
    "# filename = 'fits/rsd_analytical.json'\n",
    "\n",
    "# Write the empty dictionary to a JSON file\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(empty_dict, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ade1ded9-980e-47b2-9b4d-6a535d4a1253",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m00_R10_m00_R10 10\n",
      "m00_R10_m04_R10 10\n",
      "m00_R10_m05_R10 10\n",
      "m00_R10_m06_R10 10\n",
      "m00_R10_m07_R10 10\n",
      "m00_R10_m08_R10 10\n",
      "m00_R10_m09_R10 10\n",
      "m00_R10_m10_R10 10\n",
      "m00_R10_m11_R10 10\n",
      "m00_R10_m14_R10 10\n",
      "m00_R10_m15_R10 10\n",
      "m00_R20_m00_R20 20\n",
      "m00_R20_m04_R20 20\n",
      "m00_R20_m05_R20 20\n",
      "m00_R20_m06_R20 20\n",
      "m00_R20_m07_R20 20\n",
      "m00_R20_m08_R20 20\n",
      "m00_R20_m09_R20 20\n",
      "m00_R20_m10_R20 20\n",
      "m00_R20_m11_R20 20\n",
      "m00_R20_m14_R20 20\n",
      "m00_R20_m15_R20 20\n",
      "m00_R30_m00_R30 30\n",
      "m00_R30_m04_R30 30\n",
      "m00_R30_m05_R30 30\n",
      "m00_R30_m06_R30 30\n",
      "m00_R30_m07_R30 30\n",
      "m00_R30_m08_R30 30\n",
      "m00_R30_m09_R30 30\n",
      "m00_R30_m10_R30 30\n",
      "m00_R30_m11_R30 30\n",
      "m00_R30_m14_R30 30\n",
      "m00_R30_m15_R30 30\n",
      "m00_R50_m00_R50 50\n",
      "m00_R50_m04_R50 50\n",
      "m00_R50_m05_R50 50\n",
      "m00_R50_m06_R50 50\n",
      "m00_R50_m07_R50 50\n",
      "m00_R50_m08_R50 50\n",
      "m00_R50_m09_R50 50\n",
      "m00_R50_m10_R50 50\n",
      "m00_R50_m11_R50 50\n",
      "m00_R50_m14_R50 50\n",
      "m00_R50_m15_R50 50\n",
      "m04_R10_m04_R10 10\n",
      "m04_R20_m04_R20 20\n",
      "m04_R30_m04_R30 30\n",
      "m04_R50_m04_R50 50\n",
      "m05_R10_m05_R10 10\n",
      "m05_R20_m05_R20 20\n",
      "m05_R30_m05_R30 30\n",
      "m05_R50_m05_R50 50\n",
      "m06_R10_m06_R10 10\n",
      "m06_R20_m06_R20 20\n",
      "m06_R30_m06_R30 30\n",
      "m06_R50_m06_R50 50\n",
      "m07_R10_m07_R10 10\n",
      "m07_R20_m07_R20 20\n",
      "m07_R30_m07_R30 30\n",
      "m07_R50_m07_R50 50\n",
      "m08_R10_m08_R10 10\n",
      "m08_R20_m08_R20 20\n",
      "m08_R30_m08_R30 30\n",
      "m08_R50_m08_R50 50\n",
      "m09_R10_m09_R10 10\n",
      "m09_R20_m09_R20 20\n",
      "m09_R30_m09_R30 30\n",
      "m09_R50_m09_R50 50\n",
      "m10_R10_m10_R10 10\n",
      "m10_R20_m10_R20 20\n",
      "m10_R30_m10_R30 30\n",
      "m10_R50_m10_R50 50\n",
      "m11_R10_m11_R10 10\n",
      "m11_R20_m11_R20 20\n",
      "m11_R30_m11_R30 30\n",
      "m11_R50_m11_R50 50\n",
      "m14_R10_m14_R10 10\n",
      "m14_R20_m14_R20 20\n",
      "m14_R30_m14_R30 30\n",
      "m14_R50_m14_R50 50\n",
      "m15_R10_m15_R10 10\n",
      "m15_R20_m15_R20 20\n",
      "m15_R30_m15_R30 30\n",
      "m15_R50_m15_R50 50\n"
     ]
    }
   ],
   "source": [
    "# empty_dict = {'test': 0}\n",
    "\n",
    "# Specify the filename\n",
    "outfile = 'fits/matter_rsd_simulation.json'\n",
    "\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "for i,key in enumerate(data):\n",
    "    Cn = data[key]['Cn']\n",
    "    Rcut = data[key]['Rcut']\n",
    "    if Rcut ==15 or Rcut ==100: continue\n",
    "    for j,key2 in enumerate(data):\n",
    "        if i>j:continue\n",
    "        if Rcut != data[key2]['Rcut']: continue\n",
    "        if key!=key2 and key[:3]!='m00':continue\n",
    "        print(key+'_'+key2,Rcut)\n",
    "        Cn2 = data[key2]['Cn']\n",
    "        \n",
    "        with open(outfile, 'r') as json_file:\n",
    "            write_data = json.load(json_file)\n",
    "        try:\n",
    "            simdata = call_markspec(key,key2)\n",
    "        except:\n",
    "            print(key+'_'+key2, 'failed')\n",
    "            continue\n",
    "        new_data = {\n",
    "            key+\"_\"+key2: simdata\n",
    "        }\n",
    "        # Update the existing dictionary with the new data\n",
    "        write_data.update(new_data)\n",
    "\n",
    "        # Write the updated dictionary back to the JSON file\n",
    "        with open(outfile, 'w') as json_file:\n",
    "            json.dump(write_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1fdd-d4aa-4645-b4f0-686009bece17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc95927b-ce74-46ef-ac75-0295953e0ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBIASED TRACERS\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "BIASED TRACERS\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a23d70-3086-419a-9481-0fdee9017f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, 0, 0]\n",
      "m04\n",
      "[0, -1, 0, 0]\n",
      "R10\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R10_LRG\n",
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R20_LRG\n",
      "[0, -1, 0, 0]\n",
      "R30\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R30_LRG\n"
     ]
    }
   ],
   "source": [
    "# code to save tables for each radii \n",
    "\n",
    "# matter\n",
    "z_list = [1.1]\n",
    "mark_list = ['m04']\n",
    "Rs = [10,20,30]\n",
    "for mm in mark_list.copy():\n",
    "    for RR in Rs:\n",
    "        mark_list.append(mm+'_R%d'%RR)\n",
    "space_list = ['rsd']\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for zz in z_list:\n",
    "    for m_name in mark_list:\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        pars = get_pars('fits/rsd_bfit_pkmu.minimum.txt')\n",
    "        print(pars)\n",
    "        for ss in space_list:\n",
    "            gen_name = '%s/z%.3f/%s_LRG'%(ss,zz,m_name)\n",
    "            print(gen_name)\n",
    "            plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in k]) \n",
    "            f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "            temp_mark = mark(k,plin,nk=200,Cn=Cn,R=Rcut,name=gen_name,N=5000,basedir='.')\n",
    "            if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "            elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "            \n",
    "            stoch = False\n",
    "            if stoch: stoch_str = '_stoch'\n",
    "            else: stoch_str = ''\n",
    "            M13B_table_new = temp_mark.compute_M13B_table(pars,f,stoch=stoch)\n",
    "            M13C_table_new = temp_mark.compute_M13C_table(pars,f)\n",
    "            M22B_table_new = temp_mark.compute_M22B_table(pars,f,stoch=stoch)\n",
    "            M22C_table_new = temp_mark.compute_M22C_table(pars,f)\n",
    "            CdCdP_table_new = temp_mark.compute_CdCdP_table(pars,f)\n",
    "            stoch_SN_table = temp_mark.compute_stoch_SN_table(pars,f,stoch=stoch)\n",
    "            stoch_BSN_table = temp_mark.compute_stoch_BSN_table(pars,f)\n",
    "            stoch_dof_table = temp_mark.compute_stoch_dof_table(pars,f)\n",
    "                        \n",
    "            filename = 'output/rsd/z1.100/%s_LRG/M_tables%s.json'%(m_name[-3:],stoch_str)\n",
    "\n",
    "            dump_dict = {'M13B':M13B_table_new.tolist(),\n",
    "                         'M13C':M13C_table_new.tolist(),\n",
    "                         'M22B':M22B_table_new.tolist(),\n",
    "                         'M22C':M22C_table_new.tolist(),\n",
    "                         'CdCdP':CdCdP_table_new.tolist(),\n",
    "                         'stoch_BSN':stoch_BSN_table.tolist(),\n",
    "                         'stoch_SN':stoch_SN_table.tolist(),\n",
    "                         'stoch_dof':stoch_dof_table.tolist(),\n",
    "                         }\n",
    "            with open(filename, 'w') as fp:\n",
    "                json.dump(dump_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74195d46-2437-455f-9447-818c34f8ff95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_dict = {'test':'test'}\n",
    "# reset json file\n",
    "# filename = 'fits/matter_rsd_analytical.json'\n",
    "filename = 'fits/rsd_analytical.json'\n",
    "# filename = 'fits/rsd_analytical_stoch.json'\n",
    "\n",
    "# Write the empty dictionary to a JSON file\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(empty_dict, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1162295c-168f-44e8-b1c8-3acf7df913f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[0, -1, 0, 0]\n",
      "m04\n",
      "[0, -1, 0, 0]\n",
      "R10\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R10_LRG\n",
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R20_LRG\n",
      "[0, -1, 0, 0]\n",
      "R30\n",
      "[ 1.18544270e+00 -1.73435976e+00  4.61319081e-01  0.00000000e+00\n",
      " -3.95557780e-01  6.60393440e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.50860220e+01 -4.71798500e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R30_LRG\n"
     ]
    }
   ],
   "source": [
    "# then code to save each spectra\n",
    "z_list = [1.1]\n",
    "mark_list = ['m04']\n",
    "Rs = [10,20,30]\n",
    "for mm in mark_list.copy():\n",
    "    for RR in Rs:\n",
    "        mark_list.append(mm+'_R%d'%RR)\n",
    "\n",
    "space_list = ['rsd']\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "print('here')\n",
    "for zz in z_list:\n",
    "    for m_name in mark_list:\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        # matter \n",
    "        pars = get_pars('fits/rsd_bfit_pkmu.minimum.txt')\n",
    "        print(pars)\n",
    "        for ss in space_list:\n",
    "            # gen_name = '%s/z%.3f/%s_matter'%(ss,zz,m_name)\n",
    "            gen_name = '%s/z%.3f/%s_LRG'%(ss,zz,m_name)\n",
    "            print(gen_name)\n",
    "            plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in k]) \n",
    "            f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "            temp_mark = mark(k,plin,nk=200,Cn=Cn,R=Rcut,name=gen_name,N=5000,basedir='.')\n",
    "            if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "            elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "            \n",
    "            stoch = False\n",
    "            if stoch: stoch_str = '_stoch'\n",
    "            else: stoch_str = ''\n",
    "\n",
    "            filename = 'output/rsd/z1.100/%s_LRG/M_tables%s.json'%(m_name[-3:],stoch_str)\n",
    "            with open(filename, 'r') as json_file:\n",
    "                table_data = json.load(json_file)\n",
    "            M13B_table_new = np.array(table_data['M13B'])\n",
    "            M13C_table_new = np.array(table_data['M13C'])\n",
    "            M22B_table_new = np.array(table_data['M22B'])\n",
    "            M22C_table_new = np.array(table_data['M22C'])\n",
    "            CdCdP_table_new = np.array(table_data['CdCdP'])\n",
    "            stoch_BSN_table_new = np.array(table_data['stoch_BSN'])\n",
    "            stoch_SN_table_new = np.array(table_data['stoch_SN'])\n",
    "            stoch_dof_table_new = np.array(table_data['stoch_dof'])\n",
    "            \n",
    "            for i,key in enumerate(data):\n",
    "                if key[-3:]!=m_name[-3:]: continue\n",
    "                Cn = data[key]['Cn']\n",
    "                for j,key2 in enumerate(data):\n",
    "                    if i>j:continue\n",
    "                    if key2[-3:]!=m_name[-3:]: continue\n",
    "                    if key!=key2 and key[:3]!='m00':continue\n",
    "                    Cn2 = data[key2]['Cn']\n",
    "                    # print(key+'_'+key2,Rcut)\n",
    "                    # input to dict\n",
    "                    M13_new = combine_mark_params(Cn,M13B_table_new + M13C_table_new,change=True,Cn2=Cn2)\n",
    "                    M13B_new = combine_mark_params(Cn,M13B_table_new,change=True,Cn2=Cn2)\n",
    "                    M13C_new = combine_mark_params(Cn,M13C_table_new,change=True,Cn2=Cn2)\n",
    "                    M22_new = combine_mark_params(Cn,M22B_table_new + M22C_table_new,change=True,Cn2=Cn2)\n",
    "                    M22B_new = combine_mark_params(Cn,M22B_table_new,change=True,Cn2=Cn2)\n",
    "                    M22C_new = combine_mark_params(Cn,M22C_table_new,change=True,Cn2=Cn2)\n",
    "                    CdCdP_new = combine_mark_params(Cn,CdCdP_table_new,change=True,Cn2=Cn2)\n",
    "                    stoch_BSN_new = combine_mark_params(Cn,stoch_BSN_table_new,change=True,Cn2=Cn2)\n",
    "                    stoch_SN_new = combine_mark_params(Cn,stoch_SN_table_new,change=True,Cn2=Cn2)\n",
    "                    stoch_dof_new = combine_mark_params(Cn,stoch_dof_table_new,change=True,Cn2=Cn2)\n",
    "\n",
    "                    for table in [M13_new,M13B_new,M13C_new,M22_new,M22B_new,M22C_new,stoch_SN_new,stoch_BSN_new,stoch_dof_new]:\n",
    "                        table[3:] *= 0\n",
    "\n",
    "                    M13_new = temp_mark.poly2leg(M13_new)\n",
    "                    M13B_new = temp_mark.poly2leg(M13B_new)\n",
    "                    M13C_new = temp_mark.poly2leg(M13C_new)\n",
    "                    M22_new = temp_mark.poly2leg(M22_new)\n",
    "                    M22B_new = temp_mark.poly2leg(M22B_new)\n",
    "                    M22C_new = temp_mark.poly2leg(M22C_new)\n",
    "                    CdCdP_new = temp_mark.poly2leg(CdCdP_new)\n",
    "\n",
    "                    stoch_BSN_new = temp_mark.poly2leg(stoch_BSN_new)\n",
    "                    stoch_SN_new = temp_mark.poly2leg(stoch_SN_new)\n",
    "                    stoch_dof_new = temp_mark.poly2leg(stoch_dof_new)\n",
    "\n",
    "                    tot_M = 2*M13_new + M22_new + CdCdP_new \n",
    "                    tot_M_st = 2*M13_new + M22_new + CdCdP_new + stoch_SN_new\n",
    "\n",
    "                    # read current dict\n",
    "                    # anal_file = 'fits/matter_rsd_analytical.json'\n",
    "                    anal_file = 'fits/rsd_analytical%s.json'%stoch_str\n",
    "                    with open(anal_file, 'r') as json_file:\n",
    "                        write_data = json.load(json_file)\n",
    "\n",
    "                    # The new data to add to the dictionary\n",
    "                    new_data = {\n",
    "                        key+'_'+key2: {\n",
    "                            'k': temp_mark.kv.tolist(),\n",
    "                            'M_ell': tot_M.tolist(),\n",
    "                            'Mst_ell': tot_M_st.tolist(),\n",
    "                            'stoch_BSN_ell': stoch_BSN_new.tolist(),\n",
    "                            'stoch_SN_ell': stoch_SN_new.tolist(),\n",
    "                            'stoch_dof_ell': stoch_dof_new.tolist(),\n",
    "                            'CdCdP_ell': CdCdP_new.tolist(),\n",
    "                            'M13_ell': M13_new.tolist(),\n",
    "                            'M13B_ell': M13B_new.tolist(),\n",
    "                            'M13C_ell': M13C_new.tolist(),\n",
    "                            'M22_ell': M22_new.tolist(),\n",
    "                            'M22B_ell': M22B_new.tolist(),\n",
    "                            'M22C_ell': M22C_new.tolist(),\n",
    "                            'pars': pars.tolist()\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    # Update the existing dictionary with the new data\n",
    "                    write_data.update(new_data)\n",
    "\n",
    "                    # Write the updated dictionary back to the JSON file\n",
    "                    with open(anal_file, 'w') as json_file:\n",
    "                        json.dump(write_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c702b46-0c12-4cd3-b3de-6c252b92a063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define cov Legendre transform function\n",
    "\n",
    "def LegendreTrans_Cov(l,p,lp=None,mu_max=1.,Nk=500,Nmu=50):\n",
    "  '''\n",
    "  Returns the l'th multipole of |P(k,mu), where P(k,mu) is a \n",
    "  vector of length Nk*Nmu. Returns a vector of length Nk.\n",
    "  '''\n",
    "  if lp is None: lp = l\n",
    "  # n = self.Nk ; m = self.Nmu\n",
    "  n = Nk; m = Nmu\n",
    "  # mu = self.mu.reshape((n,m))[0]\n",
    "  mu = np.linspace(0.,1.,50)\n",
    "  # MU = np.tile(mu,Nk)\n",
    "  # mu = self.mu.reshape((n,m))[0]\n",
    "  p_reshaped = p.reshape((n,m))\n",
    "  result = np.zeros(n)\n",
    "  for i in range(n):\n",
    "     integrand = (2*l+1)*(2*lp+1)*p_reshaped[i,:]*scipy.special.legendre(l)(mu)*scipy.special.legendre(lp)(mu)\n",
    "     result[i] = scipy.integrate.simps(integrand,x=mu)\n",
    "  return result\n",
    "\n",
    "def call_markspec(m_name1,m_name2):\n",
    "    \n",
    "    simid_list = ['AbacusSummit_base_c000_ph000','AbacusSummit_base_c000_ph001','AbacusSummit_base_c000_ph002','AbacusSummit_base_c000_ph003']\n",
    "    zz = 1.1\n",
    "    ss = 'rsd'\n",
    "\n",
    "    d_pkmu_list = []\n",
    "    dd_list = []\n",
    "\n",
    "    for simid in simid_list:\n",
    "        ff = open('/mocks/results/'+simid+'/z%.3f/%s_pk3d.json'%(zz,ss))\n",
    "        # ff = open(self.datfn)\n",
    "        simdata = json.load(ff)\n",
    "        sim_k = np.array(simdata['k_binc'])\n",
    "        k = np.array(simdata['k_binc'])\n",
    "        Nk = len(k)\n",
    "        Nmu = 50\n",
    "        mu = np.linspace(0.,1.,Nmu)\n",
    "        MU = np.tile(mu,Nk)\n",
    "        dmu = list(mu[1:]-mu[:-1])\n",
    "        dmu.append(dmu[-1])\n",
    "        dmu = np.array(dmu)\n",
    "\n",
    "        dk = list(k[1:]-k[:-1])\n",
    "        dk.insert(0,dk[0])\n",
    "        dk = np.array(dk)\n",
    "        k = np.repeat(k,Nmu)\n",
    "        dk = np.repeat(dk,Nmu)\n",
    "        dmu = np.tile(dmu,Nk)\n",
    "\n",
    "        dd = simdata['LRG_%s_LRG_%s_ell'%(m_name1,m_name2)]#[:,0]\n",
    "        dd = np.array(dd)\n",
    "        dd_list.append(dd)\n",
    "        dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu),np.repeat(dd[:,2],Nmu)])\n",
    "        d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]+0.125*(35*MU**4-30*MU**2+3)*dvec[2]\n",
    "        d_pkmu_list.append(d_pkmu)\n",
    "\n",
    "\n",
    "    dd_list = np.array(dd_list)\n",
    "    d_pkmu_list = np.array(d_pkmu_list)\n",
    "    # print(np.allclose(d_ell_list[0,0],d_ell_list.reshape((len(simid_list),3*Nk))[0,:Nk]))\n",
    "    dd_avg = np.average(dd_list,axis=0)\n",
    "    d_pkmu_avg = np.average(d_pkmu_list,axis=0)\n",
    "\n",
    "    Vsurvey = (2e3)**3\n",
    "\n",
    "    prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.)\n",
    "    Cov = prefactor*2*d_pkmu_avg**2\n",
    "    knl=0.2959184739328827\n",
    "    kmin = 0.003\n",
    "    kmax = knl\n",
    "\n",
    "\n",
    "    k_constraint = (k>kmin)*(k<kmax)\n",
    "    # Cov += 1e-20\n",
    "    Cinv = 1/Cov\n",
    "    Cinv *= k_constraint\n",
    "    # Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "    save_dict = {'simid_list':simid_list,'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "                 'd_pkmu':d_pkmu_avg.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd_avg.T.tolist(), 'k':sim_k.tolist()}\n",
    "    return save_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69bf40e4-544a-40f8-940e-38200f9d5778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m00_R10_m00_R10 10\n",
      "m00_R10_m04_R10 10\n",
      "m00_R10_m05_R10 10\n",
      "m00_R10_m06_R10 10\n",
      "m00_R10_m07_R10 10\n",
      "m00_R10_m08_R10 10\n",
      "m00_R10_m09_R10 10\n",
      "m00_R10_m10_R10 10\n",
      "m00_R10_m11_R10 10\n",
      "m00_R10_m14_R10 10\n",
      "m00_R10_m15_R10 10\n",
      "m00_R20_m00_R20 20\n",
      "m00_R20_m04_R20 20\n",
      "m00_R20_m05_R20 20\n",
      "m00_R20_m06_R20 20\n",
      "m00_R20_m07_R20 20\n",
      "m00_R20_m08_R20 20\n",
      "m00_R20_m09_R20 20\n",
      "m00_R20_m10_R20 20\n",
      "m00_R20_m11_R20 20\n",
      "m00_R20_m14_R20 20\n",
      "m00_R20_m15_R20 20\n",
      "m00_R30_m00_R30 30\n",
      "m00_R30_m04_R30 30\n",
      "m00_R30_m05_R30 30\n",
      "m00_R30_m06_R30 30\n",
      "m00_R30_m07_R30 30\n",
      "m00_R30_m08_R30 30\n",
      "m00_R30_m09_R30 30\n",
      "m00_R30_m10_R30 30\n",
      "m00_R30_m11_R30 30\n",
      "m00_R30_m14_R30 30\n",
      "m00_R30_m15_R30 30\n",
      "m00_R50_m00_R50 50\n",
      "m00_R50_m04_R50 50\n",
      "m00_R50_m05_R50 50\n",
      "m00_R50_m06_R50 50\n",
      "m00_R50_m07_R50 50\n",
      "m00_R50_m08_R50 50\n",
      "m00_R50_m09_R50 50\n",
      "m00_R50_m10_R50 50\n",
      "m00_R50_m11_R50 50\n",
      "m00_R50_m14_R50 50\n",
      "m00_R50_m15_R50 50\n",
      "m04_R10_m04_R10 10\n",
      "m04_R20_m04_R20 20\n",
      "m04_R30_m04_R30 30\n",
      "m04_R50_m04_R50 50\n",
      "m05_R10_m05_R10 10\n",
      "m05_R20_m05_R20 20\n",
      "m05_R30_m05_R30 30\n",
      "m05_R50_m05_R50 50\n",
      "m06_R10_m06_R10 10\n",
      "m06_R20_m06_R20 20\n",
      "m06_R30_m06_R30 30\n",
      "m06_R50_m06_R50 50\n",
      "m07_R10_m07_R10 10\n",
      "m07_R20_m07_R20 20\n",
      "m07_R30_m07_R30 30\n",
      "m07_R50_m07_R50 50\n",
      "m08_R10_m08_R10 10\n",
      "m08_R20_m08_R20 20\n",
      "m08_R30_m08_R30 30\n",
      "m08_R50_m08_R50 50\n",
      "m09_R10_m09_R10 10\n",
      "m09_R20_m09_R20 20\n",
      "m09_R30_m09_R30 30\n",
      "m09_R50_m09_R50 50\n",
      "m10_R10_m10_R10 10\n",
      "m10_R20_m10_R20 20\n",
      "m10_R30_m10_R30 30\n",
      "m10_R50_m10_R50 50\n",
      "m11_R10_m11_R10 10\n",
      "m11_R20_m11_R20 20\n",
      "m11_R30_m11_R30 30\n",
      "m11_R50_m11_R50 50\n",
      "m14_R10_m14_R10 10\n",
      "m14_R20_m14_R20 20\n",
      "m14_R30_m14_R30 30\n",
      "m14_R50_m14_R50 50\n",
      "m15_R10_m15_R10 10\n",
      "m15_R20_m15_R20 20\n",
      "m15_R30_m15_R30 30\n",
      "m15_R50_m15_R50 50\n"
     ]
    }
   ],
   "source": [
    "#### this only runs with access to Abacus output files \n",
    "\n",
    "# empty_dict = {'test': 0}\n",
    "\n",
    "# Specify the filename\n",
    "outfile = 'fits/rsd_simulation.json'\n",
    "\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "for i,key in enumerate(data):\n",
    "    Cn = data[key]['Cn']\n",
    "    Rcut = data[key]['Rcut']\n",
    "    if Rcut ==15 or Rcut ==100: continue\n",
    "    for j,key2 in enumerate(data):\n",
    "        if i>j:continue\n",
    "        if Rcut != data[key2]['Rcut']: continue\n",
    "        if key!=key2 and key[:3]!='m00':continue\n",
    "        print(key+'_'+key2,Rcut)\n",
    "        Cn2 = data[key2]['Cn']\n",
    "        \n",
    "        with open(outfile, 'r') as json_file:\n",
    "            write_data = json.load(json_file)\n",
    "        try:\n",
    "            simdata = call_markspec(key,key2)\n",
    "        except:\n",
    "            print(key+'_'+key2, 'failed')\n",
    "            continue\n",
    "        new_data = {\n",
    "            key+\"_\"+key2: simdata\n",
    "        }\n",
    "        # Update the existing dictionary with the new data\n",
    "        write_data.update(new_data)\n",
    "\n",
    "        # Write the updated dictionary back to the JSON file\n",
    "        with open(outfile, 'w') as json_file:\n",
    "            json.dump(write_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f99cb2-e331-4c55-b0a4-3bdd08730ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
