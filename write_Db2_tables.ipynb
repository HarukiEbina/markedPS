{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9b55bb-a1f0-483e-939b-1192bc057c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "from classy import Class\n",
    "import sys\n",
    "from scipy.interpolate import interp1d\n",
    "from ept_mark import mark\n",
    "import os, json\n",
    "import time\n",
    "\n",
    "from headers_new       import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from headers_new import *\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import simps\n",
    "from velocileptors.EPT.ept_fullresum_fftw import REPT\n",
    "from headers_new import *\n",
    "import json,os,sys\n",
    "# import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f49c42-32ca-47b9-b7db-0b51b79374b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zz=1.1 \n",
    "params = {'output': 'tCl lCl mPk',\n",
    "          'l_max_scalars': 1000,\n",
    "          'lensing': 'yes',\n",
    "          'P_k_max_h/Mpc': 3.,\n",
    "          'non linear':'halofit', \n",
    "          'z_pk': '0.0,1087',\n",
    "          'A_s': 2.0830e-9,\n",
    "          'n_s': 0.9649,\n",
    "          'alpha_s': 0.,\n",
    "          'h': 0.6736,\n",
    "          'N_ur': 2.0328,\n",
    "          'N_ncdm': 1,\n",
    "          'omega_ncdm':0.00064420,\n",
    "          # 'm_ncdm': '0.01,0.05',\n",
    "          'tau_reio': 0.0544,\n",
    "          'omega_b': 0.02237,\n",
    "          'omega_cdm': 0.1200,\n",
    "          'Omega_k': 0.}\n",
    "cosmo = Class() \n",
    "cosmo.set(params) \n",
    "cosmo.compute() \n",
    "h = cosmo.pars['h']\n",
    "f = cosmo.scale_independent_growth_factor_f(zz)\n",
    "kmin = .005\n",
    "kmax = .5\n",
    "Nk = 200\n",
    "klin = np.logspace(np.log10(kmin),np.log10(kmax),Nk) # [h/Mpc]\n",
    "plin = np.array([cosmo.pk_cb_lin(kk*h,zz)*h**3. for kk in klin]) \n",
    "pars = [1,0,0,0,0,0,0,0,0,0,0]#b1, b2, bs, b3, alpha0, alpha2, alpha4, alpha6, sn, sn2, sn4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21773c33-08c5-4ef2-8494-f1ec20b3e468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_Cn_vec(Cn,Cn2=None):\n",
    "    C0, C1, C2, C3 = Cn\n",
    "    if Cn2 is None: C0_2, C1_2, C2_2, C3_2 = Cn\n",
    "    else: C0_2, C1_2, C2_2, C3_2 = Cn2\n",
    "    return [C0*C0_2, (C0*C1_2+C0_2*C1)/2, (C0* C2_2 +C0_2* C2 )/2, (C0* C3_2 +C0_2* C3 )/2,\n",
    "            C1*C1_2, (C1*C2_2+C1_2*C2)/2, (C1*C3_2+C1_2*C3)/2, C2*C2_2, (C2*C3_2+C2_2*C3)/2]\n",
    "    # return [C0**2, C0* C1, C0 *C2, C0 *C3, C1**2, C1 *C2, C1* C3, C2**2, C2*C3]\n",
    "def combine_mark_params(Cn,table,change=False,Cn2=None):\n",
    "    if change: \n",
    "        Cn_new = [Cn[i]*(-1)**i for i in range(len(Cn))]\n",
    "    else: Cn_new = Cn    \n",
    "    if Cn2 is not None: \n",
    "        if change: Cn2_new = [Cn2[i]*(-1)**i for i in range(len(Cn2))]\n",
    "        else: Cn2_new = Cn2\n",
    "    else: Cn2_new = None\n",
    "    # print(Cn_new,Cn2_new)\n",
    "    Cn_vec = get_Cn_vec(Cn_new,Cn2=Cn2_new)\n",
    "    return np.einsum('i,ijk->jk',Cn_vec,table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080ed8f8-5a9c-4ee7-a95c-73b31029810f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define cov Legendre transform function\n",
    "\n",
    "def LegendreTrans_Cov(l,p,lp=None,mu_max=1.,Nk=500,Nmu=50):\n",
    "  '''\n",
    "  Returns the l'th multipole of |P(k,mu), where P(k,mu) is a \n",
    "  vector of length Nk*Nmu. Returns a vector of length Nk.\n",
    "  '''\n",
    "  if lp is None: lp = l\n",
    "  # n = self.Nk ; m = self.Nmu\n",
    "  n = Nk; m = Nmu\n",
    "  # mu = self.mu.reshape((n,m))[0]\n",
    "  mu = np.linspace(0.,1.,50)\n",
    "  # MU = np.tile(mu,Nk)\n",
    "  # mu = self.mu.reshape((n,m))[0]\n",
    "  p_reshaped = p.reshape((n,m))\n",
    "  result = np.zeros(n)\n",
    "  for i in range(n):\n",
    "     integrand = (2*l+1)*(2*lp+1)*p_reshaped[i,:]*scipy.special.legendre(l)(mu)*scipy.special.legendre(lp)(mu)\n",
    "     result[i] = scipy.integrate.simps(integrand,x=mu)\n",
    "  return result\n",
    "def get_pars(path,EPT=True):\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "\n",
    "    # Strips the newline character\n",
    "    param_labels = Lines[0].split()\n",
    "    param_labels = param_labels[1:]\n",
    "    params = Lines[1].split()\n",
    "    \n",
    "    p_names = ['b1','b2','bs','b3','alpha0','alpha2','alpha4','alpha6','SN0','SN2','SN4']\n",
    "    LPT_params = []\n",
    "    for pp in p_names:\n",
    "        if pp in param_labels: LPT_params.append(float(params[param_labels.index(pp)]))\n",
    "        elif pp=='b1': LPT_params.append(1.)\n",
    "        else: LPT_params.append(0)\n",
    "    LPT_params[0] -= 1\n",
    "    if not EPT: return LPT_params\n",
    "    \n",
    "    EPT_params = np.zeros(len(p_names))\n",
    "    EPT_params[-7:] = LPT_params[-7:]\n",
    "    EPT_params[0] = LPT_params[0] + 1\n",
    "    EPT_params[1] = LPT_params[1] + 8/21 * LPT_params[0]\n",
    "    EPT_params[2] = LPT_params[2] - 2/7 * LPT_params[0]\n",
    "    EPT_params[3] = LPT_params[3] # just leave b3.... not sure what to do with it\n",
    "    \n",
    "    return EPT_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e1fb54-6bf1-41d1-9d36-f96ee1f3ca0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[1.9900773, -1.701457404, 0.3644986236, 0, -4.701457, 44.753394, 0, 0, 706.67817, -2550.1998, 0]\n",
      "rsd/z1.100/m04_R20_degen_Db2_original\n"
     ]
    }
   ],
   "source": [
    "# code to save tables for each radii \n",
    "\n",
    "z_list = [1.1]\n",
    "m_name = 'm04_R20'\n",
    "ss = 'rsd' \n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for zz in z_list:\n",
    "        pars = [1.9900773,-1.701457404,3.644986236e-01,0,-4.701457,44.753394 ,0,0,706.67817  ,    -2550.1998,0] # degen_loc\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        print(pars)\n",
    "        st_diff = 'Db2_original'\n",
    "        gen_name = '%s/z%.3f/%s'%(ss,zz,m_name+'_degen_'+st_diff)\n",
    "        print(gen_name)\n",
    "        # gen_name = '%s/z%.3f/%s'%(ss,zz,mm+'_degen_bias_knl_Db2')\n",
    "        temp_mark = mark(klin,plin,nk=200,Cn=Cn,name=gen_name,N=5000,basedir='.',R=Rcut)\n",
    "        # temp_mark.Nskip=Nk\n",
    "        # temp_mark.Nskip=40\n",
    "        if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "        elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "\n",
    "        stoch = False\n",
    "        M13B_table_new = temp_mark.compute_M13B_table(pars,f,stoch=stoch)\n",
    "        M13C_table_new = temp_mark.compute_M13C_table(pars,f)\n",
    "        M22B_table_new = temp_mark.compute_M22B_table(pars,f,stoch=stoch)\n",
    "        M22C_table_new = temp_mark.compute_M22C_table(pars,f)\n",
    "        CdCdP_table_new = temp_mark.compute_CdCdP_table(pars,f)\n",
    "        stoch_SN_table = temp_mark.compute_stoch_SN_table(pars,f)\n",
    "        stoch_dof_table = temp_mark.compute_stoch_dof_table(pars,f)\n",
    "\n",
    "        file_dir = 'output/%s/z%.3f/%s'%(ss,zz,m_name[-3:]+'_degen_'+st_diff)\n",
    "\n",
    "        filename = file_dir + '/M_tables.json'\n",
    "        dump_dict = {'M13B':M13B_table_new.tolist(),\n",
    "                     'M13C':M13C_table_new.tolist(),\n",
    "                     'M22B':M22B_table_new.tolist(),\n",
    "                     'M22C':M22C_table_new.tolist(),\n",
    "                     'CdCdP':CdCdP_table_new.tolist(),\n",
    "                     'stoch_SN':stoch_SN_table.tolist(),\n",
    "                     'stoch_dof':stoch_dof_table.tolist(),\n",
    "                     }\n",
    "        with open(filename, 'w') as fp:\n",
    "            json.dump(dump_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7012519-d1c8-41cd-96aa-75a1076365e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_dict = {'test':'test'}\n",
    "# reset json file\n",
    "filename = 'fits/degen_Db2_original_analytical.json'\n",
    "# filename = 'fits/rsd_analytical.json'\n",
    "\n",
    "# Write the empty dictionary to a JSON file\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(empty_dict, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb8af44-0b31-4eeb-9090-185029bfb020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "[0, -1, 0, 0]\n",
      "R20\n",
      "[ 1.99007730e+00 -1.70145740e+00  3.64498624e-01  0.00000000e+00\n",
      " -4.70145700e+00  4.47533940e+01  0.00000000e+00  0.00000000e+00\n",
      "  7.06678170e+02 -2.55019980e+03  0.00000000e+00]\n",
      "rsd/z1.100/m04_R20_degen_Db2_original\n",
      "m00_R20_m00_R20 20\n",
      "m00_R20_m04_R20 20\n",
      "m00_R20_m05_R20 20\n",
      "m00_R20_m06_R20 20\n",
      "m00_R20_m07_R20 20\n",
      "m00_R20_m08_R20 20\n",
      "m00_R20_m09_R20 20\n",
      "m00_R20_m10_R20 20\n",
      "m00_R20_m11_R20 20\n",
      "m00_R20_m14_R20 20\n",
      "m00_R20_m15_R20 20\n",
      "m04_R20_m04_R20 20\n",
      "m05_R20_m05_R20 20\n",
      "m06_R20_m06_R20 20\n",
      "m07_R20_m07_R20 20\n",
      "m08_R20_m08_R20 20\n",
      "m09_R20_m09_R20 20\n",
      "m10_R20_m10_R20 20\n",
      "m11_R20_m11_R20 20\n",
      "m14_R20_m14_R20 20\n",
      "m15_R20_m15_R20 20\n"
     ]
    }
   ],
   "source": [
    "m_name = 'm04_R20'\n",
    "# mark_list = ['m04_R30']\n",
    "ss = 'rsd' \n",
    "# space_list = ['real','rsd']\n",
    "# space_list = ['rsd']\n",
    "filename = 'mark_dict.json'\n",
    "with open(filename, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "z_list = [1.1]\n",
    "# gen_name = '%s/z%.3f/%s'%(ss,zz,mm+'_degen_'+st_diff)\n",
    "print('here')\n",
    "for zz in z_list:\n",
    "        pars = [1.9900773,-1.701457404,3.644986236e-01,0,-4.701457,44.753394 ,0,0,706.67817  ,    -2550.1998,0] # degen_loc\n",
    "        pars = np.array(pars)\n",
    "        Cn = data[m_name]['Cn']\n",
    "        Rcut = data[m_name]['Rcut']\n",
    "        print(Cn)\n",
    "        print(m_name[-3:])\n",
    "        if Rcut ==15: continue\n",
    "        print(pars)\n",
    "        # for ss in space_list:\n",
    "        # gen_name = '%s/z%.3f/%s_matter'%(ss,zz,m_name)\n",
    "        # gen_name = '%s/z%.3f/%s_LRG'%(ss,zz,m_name)\n",
    "        st_diff = 'Db2_original'\n",
    "        gen_name = '%s/z%.3f/%s'%(ss,zz,m_name+'_degen_'+st_diff)\n",
    "        print(gen_name)\n",
    "        # gen_name = '%s/z%.3f/%s'%(ss,zz,mm+'_degen_bias_knl_Db2')\n",
    "        temp_mark = mark(klin,plin,nk=200,Cn=Cn,name=gen_name,N=5000,basedir='.',R=Rcut)\n",
    "        # temp_mark.Nskip=Nk\n",
    "        # temp_mark.Nskip=40\n",
    "        if ss=='real': temp_mark.compute_tables(pars,0)\n",
    "        elif ss=='rsd': temp_mark.compute_tables(pars,f)\n",
    "        file_dir = 'output/%s/z%.3f/%s'%(ss,zz,m_name[-3:]+'_degen_'+st_diff)\n",
    "\n",
    "        filename = file_dir + '/M_tables.json'\n",
    "        with open(filename, 'r') as json_file:\n",
    "            table_data = json.load(json_file)\n",
    "        M13B_table_new = np.array(table_data['M13B'])\n",
    "        M13C_table_new = np.array(table_data['M13C'])\n",
    "        M22B_table_new = np.array(table_data['M22B'])\n",
    "        M22C_table_new = np.array(table_data['M22C'])\n",
    "        CdCdP_table_new = np.array(table_data['CdCdP'])\n",
    "        stoch_SN_table_new = np.array(table_data['stoch_SN'])\n",
    "        stoch_dof_table_new = np.array(table_data['stoch_dof'])\n",
    "\n",
    "        for i,key in enumerate(data):\n",
    "            if key[-3:]!=m_name[-3:]: continue\n",
    "            Cn = data[key]['Cn']\n",
    "            for j,key2 in enumerate(data):\n",
    "                if i>j:continue\n",
    "                if key2[-3:]!=m_name[-3:]: continue\n",
    "                if key!=key2 and key[:3]!='m00':continue\n",
    "                Cn2 = data[key2]['Cn']\n",
    "                print(key+'_'+key2,Rcut)\n",
    "                # input to dict\n",
    "                M13_new = combine_mark_params(Cn,M13B_table_new + M13C_table_new,change=True,Cn2=Cn2)\n",
    "                M13B_new = combine_mark_params(Cn,M13B_table_new,change=True,Cn2=Cn2)\n",
    "                M13C_new = combine_mark_params(Cn,M13C_table_new,change=True,Cn2=Cn2)\n",
    "                M22_new = combine_mark_params(Cn,M22B_table_new + M22C_table_new,change=True,Cn2=Cn2)\n",
    "                M22B_new = combine_mark_params(Cn,M22B_table_new,change=True,Cn2=Cn2)\n",
    "                M22C_new = combine_mark_params(Cn,M22C_table_new,change=True,Cn2=Cn2)\n",
    "                CdCdP_new = combine_mark_params(Cn,CdCdP_table_new,change=True,Cn2=Cn2)\n",
    "                stoch_SN_new = combine_mark_params(Cn,stoch_SN_table_new,change=True,Cn2=Cn2)\n",
    "                stoch_dof_new = combine_mark_params(Cn,stoch_dof_table_new,change=True,Cn2=Cn2)\n",
    "\n",
    "                for table in [M13_new,M13B_new,M13C_new,M22_new,M22B_new,M22C_new,stoch_SN_new,stoch_dof_new]:\n",
    "                    table[3:] *= 0\n",
    "\n",
    "                M13_new = temp_mark.poly2leg(M13_new)\n",
    "                M13B_new = temp_mark.poly2leg(M13B_new)\n",
    "                M13C_new = temp_mark.poly2leg(M13C_new)\n",
    "                M22_new = temp_mark.poly2leg(M22_new)\n",
    "                M22B_new = temp_mark.poly2leg(M22B_new)\n",
    "                M22C_new = temp_mark.poly2leg(M22C_new)\n",
    "                CdCdP_new = temp_mark.poly2leg(CdCdP_new)\n",
    "\n",
    "                stoch_SN_new = temp_mark.poly2leg(stoch_SN_new)\n",
    "                stoch_dof_new = temp_mark.poly2leg(stoch_dof_new)\n",
    "\n",
    "                tot_M = 2*M13_new + M22_new + CdCdP_new \n",
    "                tot_M_st = 2*M13_new + M22_new + CdCdP_new + stoch_SN_new\n",
    "\n",
    "\n",
    "                # read current dict\n",
    "                anal_file = 'fits/degen_%s_analytical.json'%st_diff\n",
    "                # anal_file = 'fits/rsd_analytical.json'\n",
    "                with open(anal_file, 'r') as json_file:\n",
    "                    write_data = json.load(json_file)\n",
    "\n",
    "                # The new data to add to the dictionary\n",
    "                new_data = {\n",
    "                    key+'_'+key2: {\n",
    "                        'k': temp_mark.kv.tolist(),\n",
    "                        'M_ell': tot_M.tolist(),\n",
    "                        'Mst_ell': tot_M_st.tolist(),\n",
    "                        'stoch_SN_ell': stoch_SN_new.tolist(),\n",
    "                        'stoch_dof_ell': stoch_dof_new.tolist(),\n",
    "                        'CdCdP_ell': CdCdP_new.tolist(),\n",
    "                        'M13_ell': M13_new.tolist(),\n",
    "                        'M13B_ell': M13B_new.tolist(),\n",
    "                        'M13C_ell': M13C_new.tolist(),\n",
    "                        'M22_ell': M22_new.tolist(),\n",
    "                        'M22B_ell': M22B_new.tolist(),\n",
    "                        'M22C_ell': M22C_new.tolist(),\n",
    "                        'pars': pars.tolist()\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                # Update the existing dictionary with the new data\n",
    "                write_data.update(new_data)\n",
    "\n",
    "                # Write the updated dictionary back to the JSON file\n",
    "                with open(anal_file, 'w') as json_file:\n",
    "                    json.dump(write_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0565e-8dab-4d3a-8b1c-2a9184698e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
